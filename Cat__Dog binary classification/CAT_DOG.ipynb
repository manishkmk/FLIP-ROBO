{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAT_DOG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxgoIsKSNBO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten,Activation\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "import pickle"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhCxnxmumXCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This block only for access o filr using google drivr\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_d0jAckvoeUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "faa572eb-bb99-4ca3-e26b-f9959b374eeb"
      },
      "source": [
        "\n",
        "import pickle\n",
        "\n",
        "pickle_in =open(r\"/content/drive/My Drive/X.pickle\",\"rb\")\n",
        "X=pickle.load(pickle_in)\n",
        "\n",
        "pickle_in =open(r\"//content/drive/My Drive/y.pickle\",\"rb\")\n",
        "y=pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X=X/255.0\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[0.4745098 ]\n",
            "   [0.6       ]\n",
            "   [0.54117647]\n",
            "   ...\n",
            "   [0.5254902 ]\n",
            "   [0.54509804]\n",
            "   [0.55686275]]\n",
            "\n",
            "  [[0.4627451 ]\n",
            "   [0.60784314]\n",
            "   [0.56470588]\n",
            "   ...\n",
            "   [0.45098039]\n",
            "   [0.48235294]\n",
            "   [0.48235294]]\n",
            "\n",
            "  [[0.47843137]\n",
            "   [0.58431373]\n",
            "   [0.55686275]\n",
            "   ...\n",
            "   [0.4       ]\n",
            "   [0.38039216]\n",
            "   [0.36078431]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.6745098 ]\n",
            "   [0.71372549]\n",
            "   [0.48627451]\n",
            "   ...\n",
            "   [0.18823529]\n",
            "   [0.16078431]\n",
            "   [0.16078431]]\n",
            "\n",
            "  [[0.76862745]\n",
            "   [0.76862745]\n",
            "   [0.63137255]\n",
            "   ...\n",
            "   [0.15686275]\n",
            "   [0.16862745]\n",
            "   [0.18431373]]\n",
            "\n",
            "  [[0.6       ]\n",
            "   [0.58823529]\n",
            "   [0.66666667]\n",
            "   ...\n",
            "   [0.17647059]\n",
            "   [0.18823529]\n",
            "   [0.18823529]]]\n",
            "\n",
            "\n",
            " [[[0.57254902]\n",
            "   [0.58823529]\n",
            "   [0.58039216]\n",
            "   ...\n",
            "   [0.16470588]\n",
            "   [0.18039216]\n",
            "   [0.14509804]]\n",
            "\n",
            "  [[0.58039216]\n",
            "   [0.58039216]\n",
            "   [0.61960784]\n",
            "   ...\n",
            "   [0.13333333]\n",
            "   [0.09803922]\n",
            "   [0.08235294]]\n",
            "\n",
            "  [[0.58431373]\n",
            "   [0.57647059]\n",
            "   [0.60784314]\n",
            "   ...\n",
            "   [0.25490196]\n",
            "   [0.24705882]\n",
            "   [0.27058824]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.37254902]\n",
            "   [0.41568627]\n",
            "   [0.41568627]\n",
            "   ...\n",
            "   [0.2627451 ]\n",
            "   [0.26666667]\n",
            "   [0.2627451 ]]\n",
            "\n",
            "  [[0.37647059]\n",
            "   [0.39215686]\n",
            "   [0.39215686]\n",
            "   ...\n",
            "   [0.27058824]\n",
            "   [0.25098039]\n",
            "   [0.24313725]]\n",
            "\n",
            "  [[0.36862745]\n",
            "   [0.37647059]\n",
            "   [0.38039216]\n",
            "   ...\n",
            "   [0.24705882]\n",
            "   [0.22745098]\n",
            "   [0.23921569]]]\n",
            "\n",
            "\n",
            " [[[0.16078431]\n",
            "   [0.25490196]\n",
            "   [0.23921569]\n",
            "   ...\n",
            "   [0.10196078]\n",
            "   [0.07058824]\n",
            "   [0.07843137]]\n",
            "\n",
            "  [[0.2       ]\n",
            "   [0.26666667]\n",
            "   [0.3254902 ]\n",
            "   ...\n",
            "   [0.12941176]\n",
            "   [0.08627451]\n",
            "   [0.08627451]]\n",
            "\n",
            "  [[0.18039216]\n",
            "   [0.29019608]\n",
            "   [0.23921569]\n",
            "   ...\n",
            "   [0.08627451]\n",
            "   [0.09019608]\n",
            "   [0.11372549]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.29803922]\n",
            "   [0.37647059]\n",
            "   [0.23529412]\n",
            "   ...\n",
            "   [0.04705882]\n",
            "   [0.05882353]\n",
            "   [0.07843137]]\n",
            "\n",
            "  [[0.14901961]\n",
            "   [0.29803922]\n",
            "   [0.3372549 ]\n",
            "   ...\n",
            "   [0.05882353]\n",
            "   [0.05490196]\n",
            "   [0.05882353]]\n",
            "\n",
            "  [[0.11764706]\n",
            "   [0.22352941]\n",
            "   [0.11372549]\n",
            "   ...\n",
            "   [0.06666667]\n",
            "   [0.05490196]\n",
            "   [0.05882353]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.78431373]\n",
            "   [0.79215686]\n",
            "   [0.78039216]\n",
            "   ...\n",
            "   [0.47843137]\n",
            "   [0.54509804]\n",
            "   [0.51764706]]\n",
            "\n",
            "  [[0.81176471]\n",
            "   [0.78039216]\n",
            "   [0.76078431]\n",
            "   ...\n",
            "   [0.4745098 ]\n",
            "   [0.55686275]\n",
            "   [0.54901961]]\n",
            "\n",
            "  [[0.80392157]\n",
            "   [0.76470588]\n",
            "   [0.76862745]\n",
            "   ...\n",
            "   [0.47843137]\n",
            "   [0.62352941]\n",
            "   [0.55686275]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.81960784]\n",
            "   [0.83529412]\n",
            "   [0.83921569]\n",
            "   ...\n",
            "   [0.89411765]\n",
            "   [0.89411765]\n",
            "   [0.88627451]]\n",
            "\n",
            "  [[0.81568627]\n",
            "   [0.80392157]\n",
            "   [0.83921569]\n",
            "   ...\n",
            "   [0.89019608]\n",
            "   [0.89019608]\n",
            "   [0.89019608]]\n",
            "\n",
            "  [[0.81568627]\n",
            "   [0.80392157]\n",
            "   [0.79607843]\n",
            "   ...\n",
            "   [0.89019608]\n",
            "   [0.87843137]\n",
            "   [0.85882353]]]\n",
            "\n",
            "\n",
            " [[[0.44313725]\n",
            "   [0.4627451 ]\n",
            "   [0.47058824]\n",
            "   ...\n",
            "   [0.25882353]\n",
            "   [0.27843137]\n",
            "   [0.2627451 ]]\n",
            "\n",
            "  [[0.42745098]\n",
            "   [0.45490196]\n",
            "   [0.47058824]\n",
            "   ...\n",
            "   [0.25490196]\n",
            "   [0.23529412]\n",
            "   [0.24313725]]\n",
            "\n",
            "  [[0.38823529]\n",
            "   [0.44705882]\n",
            "   [0.46666667]\n",
            "   ...\n",
            "   [0.27058824]\n",
            "   [0.25098039]\n",
            "   [0.16470588]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.27058824]\n",
            "   [0.26666667]\n",
            "   [0.26666667]\n",
            "   ...\n",
            "   [0.40392157]\n",
            "   [0.29411765]\n",
            "   [0.2       ]]\n",
            "\n",
            "  [[0.2745098 ]\n",
            "   [0.28235294]\n",
            "   [0.29019608]\n",
            "   ...\n",
            "   [0.45098039]\n",
            "   [0.34509804]\n",
            "   [0.22745098]]\n",
            "\n",
            "  [[0.28235294]\n",
            "   [0.28235294]\n",
            "   [0.28627451]\n",
            "   ...\n",
            "   [0.39607843]\n",
            "   [0.32941176]\n",
            "   [0.27058824]]]\n",
            "\n",
            "\n",
            " [[[0.56862745]\n",
            "   [0.56862745]\n",
            "   [0.56862745]\n",
            "   ...\n",
            "   [0.57254902]\n",
            "   [0.56862745]\n",
            "   [0.5372549 ]]\n",
            "\n",
            "  [[0.56862745]\n",
            "   [0.56862745]\n",
            "   [0.56862745]\n",
            "   ...\n",
            "   [0.54901961]\n",
            "   [0.53333333]\n",
            "   [0.50980392]]\n",
            "\n",
            "  [[0.57647059]\n",
            "   [0.57254902]\n",
            "   [0.56862745]\n",
            "   ...\n",
            "   [0.55294118]\n",
            "   [0.50196078]\n",
            "   [0.4627451 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.31372549]\n",
            "   [0.31764706]\n",
            "   [0.31372549]\n",
            "   ...\n",
            "   [0.38823529]\n",
            "   [0.38431373]\n",
            "   [0.38039216]]\n",
            "\n",
            "  [[0.31764706]\n",
            "   [0.31764706]\n",
            "   [0.31372549]\n",
            "   ...\n",
            "   [0.37647059]\n",
            "   [0.37647059]\n",
            "   [0.36862745]]\n",
            "\n",
            "  [[0.30980392]\n",
            "   [0.30196078]\n",
            "   [0.29803922]\n",
            "   ...\n",
            "   [0.36470588]\n",
            "   [0.35686275]\n",
            "   [0.36078431]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtPug_b1vz1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5D3yrtEneYy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bcafbd66-5b7e-4875-a821-689d7bb6f4f8"
      },
      "source": [
        "#first convolution extracts 32 filters that are 3x3\n",
        "#Convolution is followed by max-pooling layer with a 2x2 windows\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same',input_shape=X.shape[1:]))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#Third Convolution extract 128 filters that are 3x3\n",
        "#Convolution is followed by max-pooling layers with 2x2 windows\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#Flatten layers amp to a 1-dim tensor so we can add fully connected layers\n",
        "model.add(Flatten())\n",
        "\n",
        "#Creat a fully connected layers with Relu activation and 128 hidden layers\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#create a output layers with two nodes and sigmoid activation\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile model\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X,y,batch_size=15,epochs=30,validation_split=0.3)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17442 samples, validate on 7476 samples\n",
            "Epoch 1/30\n",
            "17442/17442 [==============================] - 26s 1ms/step - loss: 0.7110 - accuracy: 0.5157 - val_loss: 0.6918 - val_accuracy: 0.5487\n",
            "Epoch 2/30\n",
            "17442/17442 [==============================] - 26s 1ms/step - loss: 0.6866 - accuracy: 0.5429 - val_loss: 0.6884 - val_accuracy: 0.5829\n",
            "Epoch 3/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.6760 - accuracy: 0.5766 - val_loss: 0.6791 - val_accuracy: 0.6055\n",
            "Epoch 4/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.6691 - accuracy: 0.5904 - val_loss: 0.6748 - val_accuracy: 0.5911\n",
            "Epoch 5/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.6557 - accuracy: 0.6107 - val_loss: 0.6653 - val_accuracy: 0.6378\n",
            "Epoch 6/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.6430 - accuracy: 0.6250 - val_loss: 0.6478 - val_accuracy: 0.6443\n",
            "Epoch 7/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.6259 - accuracy: 0.6448 - val_loss: 0.6327 - val_accuracy: 0.6679\n",
            "Epoch 8/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.6074 - accuracy: 0.6694 - val_loss: 0.6074 - val_accuracy: 0.6903\n",
            "Epoch 9/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.5852 - accuracy: 0.6911 - val_loss: 0.6006 - val_accuracy: 0.7043\n",
            "Epoch 10/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.5667 - accuracy: 0.7118 - val_loss: 0.5587 - val_accuracy: 0.7223\n",
            "Epoch 11/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.5415 - accuracy: 0.7270 - val_loss: 0.5513 - val_accuracy: 0.7386\n",
            "Epoch 12/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.5240 - accuracy: 0.7421 - val_loss: 0.5196 - val_accuracy: 0.7465\n",
            "Epoch 13/30\n",
            "17442/17442 [==============================] - 26s 1ms/step - loss: 0.5060 - accuracy: 0.7552 - val_loss: 0.5091 - val_accuracy: 0.7529\n",
            "Epoch 14/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.4928 - accuracy: 0.7626 - val_loss: 0.4943 - val_accuracy: 0.7681\n",
            "Epoch 15/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.4698 - accuracy: 0.7788 - val_loss: 0.4754 - val_accuracy: 0.7733\n",
            "Epoch 16/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.4573 - accuracy: 0.7857 - val_loss: 0.4684 - val_accuracy: 0.7816\n",
            "Epoch 17/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.4449 - accuracy: 0.7923 - val_loss: 0.4563 - val_accuracy: 0.7857\n",
            "Epoch 18/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.4345 - accuracy: 0.7952 - val_loss: 0.4425 - val_accuracy: 0.7949\n",
            "Epoch 19/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.4173 - accuracy: 0.8093 - val_loss: 0.4402 - val_accuracy: 0.7965\n",
            "Epoch 20/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.4005 - accuracy: 0.8185 - val_loss: 0.4377 - val_accuracy: 0.7990\n",
            "Epoch 21/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.3923 - accuracy: 0.8239 - val_loss: 0.4296 - val_accuracy: 0.8022\n",
            "Epoch 22/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.3781 - accuracy: 0.8337 - val_loss: 0.4195 - val_accuracy: 0.8106\n",
            "Epoch 23/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.3653 - accuracy: 0.8381 - val_loss: 0.4189 - val_accuracy: 0.8060\n",
            "Epoch 24/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.3549 - accuracy: 0.8422 - val_loss: 0.4247 - val_accuracy: 0.8075\n",
            "Epoch 25/30\n",
            "17442/17442 [==============================] - 26s 1ms/step - loss: 0.3456 - accuracy: 0.8479 - val_loss: 0.4099 - val_accuracy: 0.8146\n",
            "Epoch 26/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.3356 - accuracy: 0.8503 - val_loss: 0.3977 - val_accuracy: 0.8214\n",
            "Epoch 27/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.3137 - accuracy: 0.8630 - val_loss: 0.4050 - val_accuracy: 0.8182\n",
            "Epoch 28/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.3072 - accuracy: 0.8678 - val_loss: 0.4071 - val_accuracy: 0.8257\n",
            "Epoch 29/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.2947 - accuracy: 0.8726 - val_loss: 0.4269 - val_accuracy: 0.8163\n",
            "Epoch 30/30\n",
            "17442/17442 [==============================] - 25s 1ms/step - loss: 0.2872 - accuracy: 0.8784 - val_loss: 0.4058 - val_accuracy: 0.8285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2e0bf6f630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuwvWeucm86n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsP0cfQMm5R7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}